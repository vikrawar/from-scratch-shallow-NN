# 2-Layer Neural Network from Scratch (NumPy)

A focused, step-by-step implementation of a 2-layer neural network (one hidden layer) using NumPy.
This notebook aims to clarify:
- How data flows through the network
- How weights and biases are updated
- How matrix multiplications transform inputs and activations

---

## ðŸ” What's Inside
- Generation of sample training data
- Explanation of the neural network's structure (input, hidden, output layers)
- Initialization of weights and biases
- Implementation of the sigmoid activation function
- Custom loss and cost functions
- Manual backpropagation for learning
- Parameter updates using gradient descent
- Visualization of the cost curve during training
- Prediction and accuracy evaluation

---

## ðŸŽ¯ Why This Project
Building a neural network from scratch provides a clear understanding of its internal workings. This notebook helps deepen intuition about how gradients flow through each layer, how weight updates impact learning, and reinforces understanding of matrix operations in neural networks.

---

## ðŸ““ Notebook
> [Open the notebook](./2-layer%20NN%20from%20Scratch.ipynb)

